{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-level GMM Error Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.mixture\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import timed_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 10492 sentences\n",
      "parse_grammar_dataset done in 0.21 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Load BEA sentences to train GMM\n",
    "@timed_func\n",
    "def parse_grammar_dataset():\n",
    "    m2_path = \"../data/BEA14/WI_LOCNESS/wi+locness/m2/A.train.gold.bea19.m2\"\n",
    "    with open(m2_path, \"r\") as f:\n",
    "        raw_lines = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    curr_item = {}\n",
    "    for line in raw_lines:\n",
    "        if line.startswith(\"S \"):\n",
    "            if len(curr_item) > 0 and len(curr_item[\"errors\"]) > 0:\n",
    "                curr_item[\"corrected_sent\"] = _correct_sentence(curr_item)\n",
    "                data.append(curr_item)\n",
    "            curr_item = {\"sentence\": line[2:].strip(), \"errors\": []}\n",
    "        elif line.startswith(\"A \"):\n",
    "            items = line.split(\"|||\")\n",
    "            start_pos_str, end_pos_str = items[0][2:].split()\n",
    "            start_pos, end_pos = int(start_pos_str), int(end_pos_str)\n",
    "            error = {\n",
    "                \"start_pos\": start_pos,  # These are in terms of word locs\n",
    "                \"end_pos\": end_pos,\n",
    "                \"correct\": items[2] \n",
    "            }\n",
    "            curr_item[\"errors\"].append(error)\n",
    "\n",
    "    print(\"Collected {} sentences\".format(len(data)))\n",
    "    sentences = [item['sentence'] for item in data]\n",
    "    return data, sentences \n",
    "\n",
    "def _correct_sentence(item):\n",
    "    \"\"\"\n",
    "    E.g., sent is \"My town is a medium size city ...\"\n",
    "    errors is [{'start_pos': 5, 'end_pos': 6, 'correct': '- sized'}]\n",
    "    Assume errors are sorted by start_pos.\n",
    "    \"\"\"\n",
    "    sent = item['sentence']\n",
    "    L = [w for w in sent.split()]\n",
    "    newline = []\n",
    "    i = 0\n",
    "    for err in item['errors']:\n",
    "        if err['start_pos'] == -1:  # This sentence is correct\n",
    "            return sent\n",
    "        newline.extend(L[i:err['start_pos']])\n",
    "        newline.append(err['correct'])\n",
    "        i = err['end_pos']\n",
    "    newline.extend(L[i:])\n",
    "    return _remove_repeated_spaces(\" \".join(newline))\n",
    "\n",
    "def _remove_repeated_spaces(s):\n",
    "    return \" \".join(s.split())\n",
    "    \n",
    "gec_data, gec_sentences = parse_grammar_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'My town is a medium size city with eighty thousand inhabitants .',\n",
       " 'errors': [{'start_pos': 5, 'end_pos': 6, 'correct': '- sized'}],\n",
       " 'corrected_sent': 'My town is a medium - sized city with eighty thousand inhabitants .'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This fact gives the government the opportunity to manage the traffic on the roads in cities or towns .',\n",
       " 'The city was deserted that night , as Michael and I wandered through the narrow streets .',\n",
       " 'Public transport is always crowded , so it is not comfortable to travel on .',\n",
       " 'The government can improve public transport by making a great investment like changing the old vehicles for new and increasing the number of buses , trains and building more bus stops and trains stations . This kind of action will help a lot to improve the quality of public transport for the population and will make the life of the people easier .',\n",
       " \"Nowadays , Easter is associated more with spring 's arrival than with religious rituals .\",\n",
       " 'I started my hobby when I was a child .',\n",
       " 'Thank you',\n",
       " 'The Great Wall is located to the north of Beijing .',\n",
       " 'I believe both are useful .',\n",
       " 'Secondly , owning a car is not a normal thing for most developing or undeveloped countries .']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_samples = np.random.choice(gec_data, 1000)\n",
    "gec_correct_sentences_train = [item['corrected_sent'] for item in gec_samples[:500]]\n",
    "gec_correct_sentences_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "model_name = 'roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An',\n",
       " 'Ġideal',\n",
       " 'istic',\n",
       " 'Ġopportunity',\n",
       " 'Ġdoes',\n",
       " 'Ġn',\n",
       " \"'t\",\n",
       " 'Ġalways',\n",
       " 'Ġlead',\n",
       " 'Ġto',\n",
       " 'Ġsuccess',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent = \"An apple a day keeps the doctors away\"\n",
    "sent = \"An idealistic opportunity does n't always lead to success.\"\n",
    "tokens = tokenizer.tokenize(sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentEncoder:\n",
    "    def __init__(self, model_name='roberta-base'):\n",
    "        self.model_name = model_name\n",
    "        self.auto_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.auto_model = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "    def _is_word_start(self, token, i):\n",
    "        if i == 0:  # For convenience of future steps\n",
    "            return False\n",
    "        if self.model_name.startswith('roberta') or self.model_name == 'gpt2':\n",
    "            return token.startswith(\"\\u0120\")\n",
    "        elif self.model_name in ['bert-base-cased', 'bert-base-multilingual-cased']:\n",
    "            return not token.startswith(\"##\")\n",
    "        else:\n",
    "            raise NotImplementedError(f\"model_name {model_name} is not supported\")\n",
    "            \n",
    "    def _find_word_tokens(self, sent, tokens):\n",
    "        if self.model_name.startswith('roberta') or self.model_name == 'gpt2':\n",
    "            return sent.split()\n",
    "        elif self.model_name in ['bert-base-cased', 'bert-base-multilingual-cased']:\n",
    "            res, buf = [], []\n",
    "            for i, token in enumerate(tokens):\n",
    "                if token.startswith(\"##\"):\n",
    "                    buf.append(token[2:])\n",
    "                else:\n",
    "                    if i > 0:\n",
    "                        res.append(\"\".join(buf))\n",
    "                    buf = [token]\n",
    "            res.append(buf)\n",
    "            return res\n",
    "        else:\n",
    "            raise NotImplementedError(f\"model_name {model_name} is not supported\")\n",
    "        \n",
    "    def encode_vecs_per_word(self, sent, add_special_tokens=False):\n",
    "        \"\"\"\n",
    "        Input: sent (str)\n",
    "        Output:\n",
    "            tokens: list (n_words) of str\n",
    "            all_hids: torch.tensor (n_words, n_layers, D)\n",
    "        This method is suitable for Transformers without adding special tokens\n",
    "        \"\"\"\n",
    "        tokens = self.auto_tokenizer.tokenize(sent)\n",
    "        start_of_word_positions = \\\n",
    "            [i for i in range(len(tokens)) if self._is_word_start(tokens[i], i)]\n",
    "        \n",
    "        if add_special_tokens:  # i.e., RoBERTa\n",
    "            sowp_list = [0] + start_of_word_positions\n",
    "            start_of_word_positions = np.array(sowp_list) + 1\n",
    "        else:\n",
    "            start_of_word_positions = np.array(start_of_word_positions)\n",
    "        word_tokens = self._find_word_tokens(sent, tokens)\n",
    "        \n",
    "        ids = torch.tensor(self.auto_tokenizer.encode(sent)).unsqueeze(0)\n",
    "        final, last, hids = self.auto_model(ids, output_hidden_states=True)\n",
    "        \n",
    "        all_hids = []\n",
    "        for layer in range(len(hids)):\n",
    "            layer_hids = []\n",
    "            i = 0\n",
    "            for pos in start_of_word_positions:\n",
    "                vecs = torch.mean(hids[layer][0:1, i:pos, :], dim=1)\n",
    "                layer_hids.append(vecs)\n",
    "                i = pos\n",
    "            vecs = torch.mean(hids[layer][0:1, i:, :], dim=1)\n",
    "            layer_hids.append(vecs)\n",
    "            lh = torch.cat(layer_hids, dim=0).unsqueeze(0)  # (1, |S|_w, D)\n",
    "            all_hids.append(lh)\n",
    "        all_hids = torch.cat(all_hids, dim=0).permute([1, 0, 2])\n",
    "        \n",
    "        assert len(word_tokens) == len(all_hids), \\\n",
    "            \"wt_len {} != transformer token len {}. word_tokens: {}\".format(\n",
    "            len(word_tokens), len(all_hids), word_tokens\n",
    "        )\n",
    "        return word_tokens, all_hids\n",
    "    \n",
    "    def contextual_token_vecs(self, sentences):\n",
    "        \"\"\"Returns: (similar shapes as src.sent_encoder.SentEncoder)\n",
    "        ret_tokens: List[List[tokens]] one list for each sentence.\n",
    "        ret_hids: List (len n. sentences) [np.array(n_words, 13, D=768)]\n",
    "        \"\"\"\n",
    "        ret_tokens, ret_hids = [], []\n",
    "        for sent in sentences:\n",
    "            tokens, hids = self.encode_vecs_per_word(sent)\n",
    "            ret_tokens.append(tokens)\n",
    "            ret_hids.append(hids.detach().cpu().numpy())\n",
    "        return ret_tokens, ret_hids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level grammar errors\n",
    "\n",
    "Look at the locations where scores are the most extraordinary\n",
    "(Let me do a token-level correlation)  \n",
    "E.g.: One sentence has 5 tokens with grammar errors: at pos 1,2,3,5,4  \n",
    "(1) The top 5 positions ranked by GMM surprisal scores, are 1,2,3,5,6  \n",
    "Then the \"token-level detection\" accuracy would be 80%.   \n",
    "(2) Is there a \"threshold\" for the GMM surprisal scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc = SentEncoder('roberta-base')\n",
    "#enc = SentEncoder('gpt2')\n",
    "enc = SentEncoder('bert-base-cased')\n",
    "#enc = SentEncoder('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 ['An', 'idealistic', 'opportunity', 'does', 'n', \"'\", 't', 'work', ['.']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 13, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_sent = \"My town is a medium size city with eighty thousand inhabitants .\\n\"\n",
    "test_sent = \"An idealistic opportunity does n't work.\"\n",
    "raw_tokens, vecs = enc.encode_vecs_per_word(test_sent)\n",
    "print(len(raw_tokens), raw_tokens)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-15.0468, grad_fn=<MinBackward1>),\n",
       " tensor(26.8665, grad_fn=<MaxBackward1>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.min(), vecs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, all_vecs = enc.contextual_token_vecs(gec_correct_sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 133)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lens = [len(item) for item in all_vecs]\n",
    "np.min(all_lens), np.max(all_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 13, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vecs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[np.min(vec) for vec in all_vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyModel:\n",
    "    \"\"\"Model that uses GMM on embeddings generated by BERT for finding syntactic\n",
    "    or semantic anomalies.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_sentences, encoder_model='roberta-base'):\n",
    "        self.enc = SentEncoder(encoder_model)\n",
    "        self.gmms = []\n",
    "\n",
    "        _, all_vecs = self.enc.contextual_token_vecs(train_sentences)\n",
    "        for layer in range(13):\n",
    "            sent_vecs = np.vstack([vs[:,layer,:] for vs in all_vecs])\n",
    "            gmm = sklearn.mixture.GaussianMixture()\n",
    "            gmm.fit(sent_vecs)\n",
    "            self.gmms.append(gmm)\n",
    "\n",
    "\n",
    "    def gmm_score(self, sentences):\n",
    "        \"\"\"Returns (all_tokens, all_scores), where\n",
    "        all_tokens is List[List[token]]\n",
    "        all_scores is List[np.array(num layers, |S|)]\n",
    "        \"\"\"\n",
    "\n",
    "        all_tokens, all_vecs = self.enc.contextual_token_vecs(sentences)\n",
    "        all_scores = []\n",
    "\n",
    "        for sent_ix in range(len(sentences)):\n",
    "            tokens = all_tokens[sent_ix]\n",
    "            vecs = all_vecs[sent_ix]\n",
    "            assert len(tokens) == vecs.shape[0]\n",
    "\n",
    "            layer_scores = []\n",
    "            for layer in range(13):\n",
    "                scores = self.gmms[layer].score_samples(vecs[:, layer, :])\n",
    "                layer_scores.append(scores)\n",
    "\n",
    "            all_scores.append(np.array(layer_scores))\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_model = AnomalyModel(gec_correct_sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = gec_samples[500:510]\n",
    "test_sentences = [item['sentence'] for item in test_samples]\n",
    "all_tokens, gmm_scores = anomaly_model.gmm_score(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_layer_scores(sample):\n",
    "    sent = sample['sentence']\n",
    "    pp.pprint(sample)\n",
    "    tokens, all_layer = anomaly_model.gmm_score([sent])\n",
    "    tokens = tokens[0]\n",
    "    all_layer = all_layer[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(all_layer, origin='lower')\n",
    "    plt.xticks(range(len(tokens)), tokens, rotation='vertical')\n",
    "    plt.yticks(range(12), range(12))\n",
    "    plt.ylabel('Layer')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'corrected_sent': 'You have asked for a waiter in your cafe .',\n",
      " 'errors': [{'correct': 'for', 'end_pos': 4, 'start_pos': 3},\n",
      "            {'correct': 'waiter', 'end_pos': 6, 'start_pos': 5}],\n",
      " 'sentence': 'You have asked about a server in your cafe .'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_layer_scores(test_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among 1000 samples, 1000 (100.00%) have matched lens from two methods.\n",
      "verify_lengths done in 102.41 seconds.\n"
     ]
    }
   ],
   "source": [
    "@timed_func\n",
    "def verify_lengths(samples):\n",
    "    \"\"\"\n",
    "    Note: This works for RoBERTa and GPT2. BERT splits e.g., n't into 3 tokens. So we\n",
    "    should rely on the len(all_tokens[i]) given by the SentEncoder.\n",
    "    \"\"\"\n",
    "    test_sentences = [item['sentence'] for item in samples]\n",
    "    all_tokens, gmm_scores = anomaly_model.gmm_score(test_sentences)\n",
    "    # Verify if the token lengths match sample sentence lengths\n",
    "\n",
    "    equal = 0\n",
    "    for i, sample in enumerate(samples):\n",
    "        st_word_len = len(all_tokens[i])  # Given by transformers\n",
    "        tr_word_len = len(test_sentences[i].split())  # Input sentence\n",
    "        if tr_word_len == st_word_len:\n",
    "            equal += 1\n",
    "    print(\"Among {} samples, {} ({:.2f}%) have matched lens from two methods.\".format(\n",
    "        len(samples), equal, equal / len(samples) * 100\n",
    "    ))\n",
    "    \n",
    "verify_lengths(gec_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Layer 0=====\n",
      "Correct words (total 7617): avg score: 234.68, std 625.88\n",
      "Incorrect words (total 1402): avg score: 10.98, std 732.24\n",
      "Mann Whitney U test: p=2.427541425815511e-26. Different distributions.\n",
      "=====Layer 1=====\n",
      "Correct words (total 7617): avg score: -126.04, std 357.21\n",
      "Incorrect words (total 1402): avg score: -252.05, std 393.95\n",
      "Mann Whitney U test: p=3.214187967009049e-33. Different distributions.\n",
      "=====Layer 2=====\n",
      "Correct words (total 7617): avg score: -163.72, std 264.42\n",
      "Incorrect words (total 1402): avg score: -254.97, std 265.19\n",
      "Mann Whitney U test: p=4.902447826084232e-37. Different distributions.\n",
      "=====Layer 3=====\n",
      "Correct words (total 7617): avg score: -145.88, std 214.49\n",
      "Incorrect words (total 1402): avg score: -231.61, std 197.12\n",
      "Mann Whitney U test: p=5.1862277392489386e-52. Different distributions.\n",
      "=====Layer 4=====\n",
      "Correct words (total 7617): avg score: -144.94, std 206.44\n",
      "Incorrect words (total 1402): avg score: -226.60, std 175.94\n",
      "Mann Whitney U test: p=1.6679995616837905e-55. Different distributions.\n",
      "=====Layer 5=====\n",
      "Correct words (total 7617): avg score: -203.12, std 199.78\n",
      "Incorrect words (total 1402): avg score: -294.09, std 170.80\n",
      "Mann Whitney U test: p=3.217257322741108e-69. Different distributions.\n",
      "=====Layer 6=====\n",
      "Correct words (total 7617): avg score: -188.45, std 191.42\n",
      "Incorrect words (total 1402): avg score: -275.89, std 166.27\n",
      "Mann Whitney U test: p=5.567940460930247e-68. Different distributions.\n",
      "=====Layer 7=====\n",
      "Correct words (total 7617): avg score: -200.51, std 182.75\n",
      "Incorrect words (total 1402): avg score: -283.17, std 158.39\n",
      "Mann Whitney U test: p=5.491516063127831e-68. Different distributions.\n",
      "=====Layer 8=====\n",
      "Correct words (total 7617): avg score: -229.04, std 176.49\n",
      "Incorrect words (total 1402): avg score: -303.31, std 153.40\n",
      "Mann Whitney U test: p=1.5985371652362302e-58. Different distributions.\n",
      "=====Layer 9=====\n",
      "Correct words (total 7617): avg score: -252.06, std 188.60\n",
      "Incorrect words (total 1402): avg score: -337.66, std 171.71\n",
      "Mann Whitney U test: p=2.6782486211590454e-65. Different distributions.\n",
      "=====Layer 10=====\n",
      "Correct words (total 7617): avg score: -202.75, std 205.37\n",
      "Incorrect words (total 1402): avg score: -332.59, std 224.99\n",
      "Mann Whitney U test: p=3.361997331419623e-99. Different distributions.\n",
      "=====Layer 11=====\n",
      "Correct words (total 7617): avg score: -121.82, std 203.90\n",
      "Incorrect words (total 1402): avg score: -267.44, std 259.14\n",
      "Mann Whitney U test: p=8.844126839343168e-108. Different distributions.\n",
      "=====Layer 12=====\n",
      "Correct words (total 7617): avg score: 554.40, std 233.58\n",
      "Incorrect words (total 1402): avg score: 484.81, std 260.40\n",
      "Mann Whitney U test: p=2.6748857071849844e-31. Different distributions.\n",
      "true_false_bin done in 45.79 seconds.\n"
     ]
    }
   ],
   "source": [
    "@timed_func\n",
    "def true_false_bin(samples):\n",
    "    test_sentences = [item['sentence'] for item in samples]\n",
    "    all_tokens, gmm_scores = anomaly_model.gmm_score(test_sentences)\n",
    "    \n",
    "    for layer in range(13):\n",
    "        print (\"=====Layer {}=====\".format(layer))\n",
    "        scores_correct, scores_typo = [], []\n",
    "        for i, sample in enumerate(samples):\n",
    "            if sample['errors'][0]['start_pos'] == -1:  # This sentence is correct\n",
    "                scores_correct += gmm_scores[i][layer].tolist()\n",
    "            else:\n",
    "                # These T/F sentinels mark the errors of this sentence\n",
    "                st_word_len = len(all_tokens[i])\n",
    "                \n",
    "                sentinels = np.ones(st_word_len)\n",
    "                for gerr in sample['errors']:\n",
    "                    sentinels[gerr['start_pos']: gerr['end_pos']] = 0  # broadcast\n",
    "                \n",
    "                for j in range(len(sentinels)):\n",
    "                    if sentinels[j]:\n",
    "                        scores_correct.append(gmm_scores[i][layer,j])\n",
    "                    else:\n",
    "                        scores_typo.append(gmm_scores[i][layer,j])\n",
    "        print (\"Correct words (total {}): avg score: {:.2f}, std {:.2f}\".format(\n",
    "            len(scores_correct),\n",
    "            np.mean(scores_correct), np.std(scores_correct)\n",
    "        ))\n",
    "        print (\"Incorrect words (total {}): avg score: {:.2f}, std {:.2f}\".format(\n",
    "            len(scores_typo),\n",
    "            np.mean(scores_typo), np.std(scores_typo)\n",
    "        ))\n",
    "        stat, p = mannwhitneyu(scores_correct, scores_typo)\n",
    "        # https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/\n",
    "        # Non-normal for both arrays\n",
    "        u_test_res = \"Same\" if p>0.05 else \"Different\"\n",
    "        print (\"Mann Whitney U test: p={}. {} distributions.\".format(p, u_test_res))\n",
    "        \n",
    "true_false_bin(gec_samples[500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations up till now:  \n",
    "1. There are separations between the GMM scores for \"correct words\" and \"incorrect words\".  \n",
    "2. Except for layer 12, the `p` values in general decrease as layers go up. This might indicate that higher layers are more surprised at grammar errors.  \n",
    "3. The large std indicate that there might not be a clear-cut threshold, for us to say \"when the surprisal score is beyond / below this threshold, this is grammar error\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level grammar error detection\n",
    "- Now that I have the surprisal score and the true labels. Evaluate on (1) the ROC curve, (2) report the ROC_AUC_score  \n",
    "- This can be a baseline metric to contrast to residualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "@timed_func\n",
    "def ged_evaluation(anomaly_model, samples):\n",
    "    test_sentences = [item['sentence'] for item in samples]\n",
    "    all_tokens, gmm_scores = anomaly_model.gmm_score(test_sentences)\n",
    "    \n",
    "    for layer in range(13):\n",
    "        pred_scores = []\n",
    "        y_true = []\n",
    "        for i, sample in enumerate(samples):\n",
    "            st_word_len = len(all_tokens[i])\n",
    "            \n",
    "            if sample['errors'][0]['start_pos'] == -1:  # This sentence is ok\n",
    "                y_true += [1] * st_word_len\n",
    "            else:\n",
    "                sentinels = np.ones(st_word_len)\n",
    "                for gerr in sample['errors']:\n",
    "                    sentinels[gerr['start_pos']: gerr['end_pos']] = 0  # broadcast\n",
    "                y_true += sentinels.tolist()\n",
    "            pred_scores += gmm_scores[i][layer].tolist()\n",
    "                \n",
    "        auroc = roc_auc_score(y_true, pred_scores)\n",
    "        print (\"Layer {} AUROC {:.4f}\".format(layer, auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Model: bert-base-multilingual-cased ###\n",
      "Layer 0 AUROC 0.5425\n",
      "Layer 1 AUROC 0.5429\n",
      "Layer 2 AUROC 0.5513\n",
      "Layer 3 AUROC 0.5553\n",
      "Layer 4 AUROC 0.5597\n",
      "Layer 5 AUROC 0.5610\n",
      "Layer 6 AUROC 0.5610\n",
      "Layer 7 AUROC 0.5762\n",
      "Layer 8 AUROC 0.5800\n",
      "Layer 9 AUROC 0.5819\n",
      "Layer 10 AUROC 0.5802\n",
      "Layer 11 AUROC 0.5774\n",
      "Layer 12 AUROC 0.5357\n",
      "ged_evaluation done in 78.12 seconds.\n",
      "\n",
      " ### Model: bert-base-cased ###\n",
      "Layer 0 AUROC 0.5360\n",
      "Layer 1 AUROC 0.5373\n",
      "Layer 2 AUROC 0.5471\n",
      "Layer 3 AUROC 0.5561\n",
      "Layer 4 AUROC 0.5597\n",
      "Layer 5 AUROC 0.5649\n",
      "Layer 6 AUROC 0.5685\n",
      "Layer 7 AUROC 0.5724\n",
      "Layer 8 AUROC 0.5729\n",
      "Layer 9 AUROC 0.5714\n",
      "Layer 10 AUROC 0.5708\n",
      "Layer 11 AUROC 0.5725\n",
      "Layer 12 AUROC 0.5217\n",
      "ged_evaluation done in 52.33 seconds.\n",
      "\n",
      " ### Model: roberta-base ###\n",
      "Layer 0 AUROC 0.5419\n",
      "Layer 1 AUROC 0.5532\n",
      "Layer 2 AUROC 0.5643\n",
      "Layer 3 AUROC 0.5610\n",
      "Layer 4 AUROC 0.5593\n",
      "Layer 5 AUROC 0.5689\n",
      "Layer 6 AUROC 0.5699\n",
      "Layer 7 AUROC 0.5767\n",
      "Layer 8 AUROC 0.5645\n",
      "Layer 9 AUROC 0.5718\n",
      "Layer 10 AUROC 0.5979\n",
      "Layer 11 AUROC 0.6002\n",
      "Layer 12 AUROC 0.5520\n",
      "ged_evaluation done in 56.40 seconds.\n",
      "\n",
      " ### Model: gpt2 ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 AUROC 0.6038\n",
      "Layer 1 AUROC 0.5954\n",
      "Layer 2 AUROC 0.5968\n",
      "Layer 3 AUROC 0.5974\n",
      "Layer 4 AUROC 0.5952\n",
      "Layer 5 AUROC 0.5895\n",
      "Layer 6 AUROC 0.5921\n",
      "Layer 7 AUROC 0.5872\n",
      "Layer 8 AUROC 0.5893\n",
      "Layer 9 AUROC 0.5842\n",
      "Layer 10 AUROC 0.5735\n",
      "Layer 11 AUROC 0.5582\n",
      "Layer 12 AUROC 0.5818\n",
      "ged_evaluation done in 54.31 seconds.\n"
     ]
    }
   ],
   "source": [
    "for model_name in ['bert-base-multilingual-cased', 'bert-base-cased', 'roberta-base', 'gpt2']:\n",
    "    print(\"\\n ### Model: {} ###\".format(model_name))\n",
    "    anomaly_model = AnomalyModel(gec_correct_sentences_train, model_name)\n",
    "    ged_evaluation(anomaly_model, gec_samples[500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level grammar error detection with residualization\n",
    "\n",
    "This is not compatible with the GMM setting, because:  \n",
    "Let representations be $X$, frequency be $c$, target (grammar correctness) be $Y$, then the GMM implicitly learns $P_\\theta(Y|X;c)$. Note that is is **not** possible to get $P_\\theta(Y|X;c=Const)$ in this unsupervised setting. Let's proceed without the residualization idea.  \n",
    "\n",
    "One potential idea, training a separate $q(Y|X;c)$ with an MLP, then taking $q(Y|X;c=Const)$ as the real $q(Y|X)$, is not relevant to GMM, and is not unsupervised.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
