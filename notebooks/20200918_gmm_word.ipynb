{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-level GMM Error Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.mixture\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import timed_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 10492 sentences\n",
      "parse_grammar_dataset done in 0.22 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Load BEA sentences to train GMM\n",
    "@timed_func\n",
    "def parse_grammar_dataset():\n",
    "    m2_path = \"../data/BEA14/WI_LOCNESS/wi+locness/m2/A.train.gold.bea19.m2\"\n",
    "    with open(m2_path, \"r\") as f:\n",
    "        raw_lines = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    curr_item = {}\n",
    "    for line in raw_lines:\n",
    "        if line.startswith(\"S \"):\n",
    "            if len(curr_item) > 0 and len(curr_item[\"errors\"]) > 0:\n",
    "                curr_item[\"corrected_sent\"] = _correct_sentence(curr_item)\n",
    "                data.append(curr_item)\n",
    "            curr_item = {\"sentence\": line[2:], \"errors\": []}\n",
    "        elif line.startswith(\"A \"):\n",
    "            items = line.split(\"|||\")\n",
    "            start_pos_str, end_pos_str = items[0][2:].split()\n",
    "            start_pos, end_pos = int(start_pos_str), int(end_pos_str)\n",
    "            error = {\n",
    "                \"start_pos\": start_pos,  # These are in terms of word locs\n",
    "                \"end_pos\": end_pos,\n",
    "                \"correct\": items[2] \n",
    "            }\n",
    "            curr_item[\"errors\"].append(error)\n",
    "\n",
    "    print(\"Collected {} sentences\".format(len(data)))\n",
    "    sentences = [item['sentence'] for item in data]\n",
    "    return data, sentences \n",
    "\n",
    "def _correct_sentence(item):\n",
    "    \"\"\"\n",
    "    E.g., sent is \"My town is a medium size city ...\"\n",
    "    errors is [{'start_pos': 5, 'end_pos': 6, 'correct': '- sized'}]\n",
    "    Assume errors are sorted by start_pos.\n",
    "    \"\"\"\n",
    "    sent = item['sentence']\n",
    "    L = sent.split()\n",
    "    newline = []\n",
    "    i = 0\n",
    "    for err in item['errors']:\n",
    "        if err['start_pos'] == -1:  # This sentence is correct\n",
    "            return sent\n",
    "        newline.extend(L[i:err['start_pos']])\n",
    "        newline.append(err['correct'])\n",
    "        i = err['end_pos']\n",
    "    newline.extend(L[i:])\n",
    "    return \" \".join(newline)\n",
    "    \n",
    "gec_data, gec_sentences = parse_grammar_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'My town is a medium size city with eighty thousand inhabitants .\\n',\n",
       " 'errors': [{'start_pos': 5, 'end_pos': 6, 'correct': '- sized'}],\n",
       " 'corrected_sent': 'My town is a medium - sized city with eighty thousand inhabitants .'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I agree with your parents , maybe you could spend your money on something you really need and maybe you can buy computer games with the money you have left , or maybe you could put aside the money to buy something really important to you .',\n",
       " 'First of all , a boat travels on the sea and the sea is very beautiful .',\n",
       " 'I am so happy you have finally decided to visit my country .\\n',\n",
       " 'After the exams finished , I went home and had nothing to do , so I thought that I needed to watch my dramas because it was a week since I had watched them due to the exam week .',\n",
       " 'Washing you enjoy it .',\n",
       " \"They 're more for self - defense , but  what I do , and my way to stay healthy , is martial arts and running .\",\n",
       " 'We were very happy there . We really liked Taxco .',\n",
       " 'The future of transport is  public , because there will be less traffic .',\n",
       " 'I am writing to apply for the job of camp organizer .\\n',\n",
       " \"Hi Alex , I ca n't wait   to see you\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_samples = np.random.choice(gec_data, 1000)\n",
    "gec_correct_sentences_train = [item['corrected_sent'] for item in gec_samples[:500]]\n",
    "gec_correct_sentences_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "model_name = 'roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An',\n",
       " 'Ġideal',\n",
       " 'istic',\n",
       " 'Ġopportunity',\n",
       " 'Ġdoes',\n",
       " 'Ġn',\n",
       " \"'t\",\n",
       " 'Ġalways',\n",
       " 'Ġlead',\n",
       " 'Ġto',\n",
       " 'Ġsuccess',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent = \"An apple a day keeps the doctors away\"\n",
    "sent = \"An idealistic opportunity does n't always lead to success.\"\n",
    "tokens = tokenizer.tokenize(sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentEncoder:\n",
    "    def __init__(self, model_name='roberta-base'):\n",
    "        self.model_name = model_name\n",
    "        self.auto_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.auto_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def encode_vecs_per_word(self, sent, include_sos_eos=False):\n",
    "        \"\"\"\n",
    "        Input: sent (str)\n",
    "        Output: \n",
    "            tokens: list (n_words + 2) of str\n",
    "            all_hids: torch.tensor (n_words + 2, 13, D), where \n",
    "                the additional 2 tokens are <s> and </s> that RoBERTa adds.\n",
    "        \"\"\"\n",
    "        tokens = self.auto_tokenizer.tokenize(sent)\n",
    "        start_of_word_positions = np.array(\n",
    "            [i for i in range(len(tokens)) if tokens[i].startswith(\"Ġ\") or i==0]\n",
    "        )  \n",
    "        word_tokens, start_of_word_positions = ['<s>'], []\n",
    "        wt_buffer = []\n",
    "        for i, t in enumerate(tokens):\n",
    "            if i == 0:\n",
    "                wt_buffer = [t]\n",
    "                start_of_word_positions.append(i)\n",
    "            elif t.startswith(\"Ġ\"):\n",
    "                # This is RoBERTa-specific\n",
    "                # Except for the first word, all tokens that are start of words\n",
    "                # are marked with a \"Ġ\".\n",
    "                word_tokens.append(\"\".join(wt_buffer))\n",
    "                start_of_word_positions.append(i)\n",
    "                wt_buffer = [t[1:]]\n",
    "            else:\n",
    "                wt_buffer.append(t)\n",
    "        word_tokens.append(\"\".join(wt_buffer))\n",
    "        word_tokens.append('</s>')\n",
    "        start_of_word_positions = 1 + np.array(start_of_word_positions)\n",
    "        \n",
    "        ids = torch.tensor(self.auto_tokenizer.encode(sent)).unsqueeze(0)\n",
    "        final, last, hids = self.auto_model(ids, output_hidden_states=True)\n",
    "        # hids is List (len 13) of torch.tensor (bsz=1, token_len+2, D)\n",
    "\n",
    "        all_hids = []\n",
    "        for layer in range(len(hids)):\n",
    "            layer_hids = []\n",
    "            \n",
    "            i = 0\n",
    "            for pos in start_of_word_positions.tolist() + [len(hids[0][0])]:\n",
    "                vecs = torch.mean(hids[layer][0:1, i:pos,:], dim=1)\n",
    "                layer_hids.append(vecs)\n",
    "                i = pos\n",
    "            layer_hids.append(hids[layer][0:1, -1, :])\n",
    "            \n",
    "            lh = torch.cat(layer_hids, dim=0).unsqueeze(0)\n",
    "            all_hids.append(lh)\n",
    "            \n",
    "        all_hids = torch.cat(all_hids, dim=0).permute([1, 0, 2])\n",
    "        if not include_sos_eos:\n",
    "            return word_tokens[1:-1], all_hids[1:-1, :, :]\n",
    "        else:\n",
    "            return word_tokens, all_hids\n",
    "    \n",
    "    def contextual_token_vecs(self, sentences):\n",
    "        \"\"\"Returns: (similar shapes as src.sent_encoder.SentEncoder)\n",
    "        ret_tokens: List[List[tokens]] one list for each sentence.\n",
    "        ret_hids: List (len n. sentences) [np.array(n_words, 13, D=768)]\n",
    "        \"\"\"\n",
    "        ret_tokens, ret_hids = [], []\n",
    "        for sent in sentences:\n",
    "            tokens, hids = self.encode_vecs_per_word(sent)\n",
    "            ret_tokens.append(tokens)\n",
    "            ret_hids.append(hids.detach().cpu().numpy())\n",
    "        return ret_tokens, ret_hids\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level grammar errors\n",
    "\n",
    "Look at the locations where scores are the most extraordinary\n",
    "(Let me do a token-level correlation)  \n",
    "E.g.: One sentence has 5 tokens with grammar errors: at pos 1,2,3,5,4  \n",
    "(1) The top 5 positions ranked by GMM surprisal scores, are 1,2,3,5,6  \n",
    "Then the \"token-level detection\" accuracy would be 80%.  \n",
    "(2) Is there a \"threshold\" for the GMM surprisal scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = SentEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 ['An', 'idealistic', 'opportunity', 'does', \"n't\", 'work.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 13, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_sent = \"My town is a medium size city with eighty thousand inhabitants .\\n\"\n",
    "test_sent = \"An idealistic opportunity does n't work.\"\n",
    "raw_tokens, vecs = enc.encode_vecs_per_word(test_sent)\n",
    "print(len(raw_tokens), raw_tokens)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyModel:\n",
    "    \"\"\"Model that uses GMM on embeddings generated by BERT for finding syntactic\n",
    "    or semantic anomalies.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_sentences):\n",
    "        self.enc = SentEncoder()\n",
    "        self.gmms = []\n",
    "\n",
    "        _, all_vecs = self.enc.contextual_token_vecs(train_sentences)\n",
    "        for layer in range(13):\n",
    "            sent_vecs = np.vstack([vs[:,layer,:] for vs in all_vecs])\n",
    "            gmm = sklearn.mixture.GaussianMixture()\n",
    "            gmm.fit(sent_vecs)\n",
    "            self.gmms.append(gmm)\n",
    "\n",
    "\n",
    "    def gmm_score(self, sentences):\n",
    "        \"\"\"Returns (all_tokens, all_scores), where\n",
    "        all_tokens is List[List[token]]\n",
    "        all_scores is List[np.array(num layers, |S|)]\n",
    "        \"\"\"\n",
    "\n",
    "        all_tokens, all_vecs = self.enc.contextual_token_vecs(sentences)\n",
    "        all_scores = []\n",
    "\n",
    "        for sent_ix in range(len(sentences)):\n",
    "            tokens = all_tokens[sent_ix]\n",
    "            vecs = all_vecs[sent_ix]\n",
    "            assert len(tokens) == vecs.shape[0]\n",
    "\n",
    "            layer_scores = []\n",
    "            for layer in range(13):\n",
    "                scores = self.gmms[layer].score_samples(vecs[:, layer, :])\n",
    "                layer_scores.append(scores)\n",
    "\n",
    "            all_scores.append(np.array(layer_scores))\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_model = AnomalyModel(gec_correct_sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = gec_samples[500:510]\n",
    "test_sentences = [item['sentence'] for item in test_samples]\n",
    "all_tokens, gmm_scores = anomaly_model.gmm_score(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_layer_scores(sample):\n",
    "    sent = sample['sentence']\n",
    "    pp.pprint(sample)\n",
    "    tokens, all_layer = anomaly_model.gmm_score([sent])\n",
    "    tokens = tokens[0]\n",
    "    all_layer = all_layer[0]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(all_layer, origin='lower')\n",
    "    plt.xticks(range(len(tokens)), tokens, rotation='vertical')\n",
    "    plt.yticks(range(12), range(12))\n",
    "    plt.ylabel('Layer')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'corrected_sent': 'transport in Sudan is so expensive . We suffer from the '\n",
      "                   'less and expensive transport here .',\n",
      " 'errors': [{'correct': 'in', 'end_pos': 2, 'start_pos': 1},\n",
      "            {'correct': '. We', 'end_pos': 7, 'start_pos': 6}],\n",
      " 'sentence': 'transport at Sudan is so expensive we suffer from the less and '\n",
      "             'expensive transport here .\\n'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_layer_scores(test_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among 1000 samples, 1000 (100.00%) have matched lens from two methods.\n",
      "verify_lengths done in 129.23 seconds.\n"
     ]
    }
   ],
   "source": [
    "@timed_func\n",
    "def verify_lengths(samples):\n",
    "    test_sentences = [item['sentence'] for item in samples]\n",
    "    all_tokens, gmm_scores = anomaly_model.gmm_score(test_sentences)\n",
    "    # Verify if the token lengths match sample sentence lengths\n",
    "\n",
    "    equal = 0\n",
    "    for i, sample in enumerate(samples):\n",
    "        tr_word_len = len(all_tokens[i])  # Given by transformers\n",
    "        st_word_len = len(test_sentences[i].split())  # Input sentence\n",
    "        if tr_word_len == st_word_len:\n",
    "            equal += 1\n",
    "        #print(\"\\ntr: {}, st: {}\".format(tr_word_len, st_word_len))\n",
    "        #print(\"tr: {}, st: {}\".format(all_tokens[i], test_sentences[i].split()))\n",
    "    print(\"Among {} samples, {} ({:.2f}%) have matched lens from two methods.\".format(\n",
    "        len(samples), equal, equal / len(samples) * 100\n",
    "    ))\n",
    "    \n",
    "verify_lengths(gec_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Layer 0=====\n",
      "Correct words (total 7617): avg score: 234.68, std 625.88\n",
      "Incorrect words (total 1402): avg score: 10.98, std 732.24\n",
      "Mann Whitney U test: p=2.427541425815511e-26. Different distributions.\n",
      "=====Layer 1=====\n",
      "Correct words (total 7617): avg score: -126.04, std 357.21\n",
      "Incorrect words (total 1402): avg score: -252.05, std 393.95\n",
      "Mann Whitney U test: p=3.214187967009049e-33. Different distributions.\n",
      "=====Layer 2=====\n",
      "Correct words (total 7617): avg score: -163.72, std 264.42\n",
      "Incorrect words (total 1402): avg score: -254.97, std 265.19\n",
      "Mann Whitney U test: p=4.902447826084232e-37. Different distributions.\n",
      "=====Layer 3=====\n",
      "Correct words (total 7617): avg score: -145.88, std 214.49\n",
      "Incorrect words (total 1402): avg score: -231.61, std 197.12\n",
      "Mann Whitney U test: p=5.1862277392489386e-52. Different distributions.\n",
      "=====Layer 4=====\n",
      "Correct words (total 7617): avg score: -144.94, std 206.44\n",
      "Incorrect words (total 1402): avg score: -226.60, std 175.94\n",
      "Mann Whitney U test: p=1.6679995616837905e-55. Different distributions.\n",
      "=====Layer 5=====\n",
      "Correct words (total 7617): avg score: -203.12, std 199.78\n",
      "Incorrect words (total 1402): avg score: -294.09, std 170.80\n",
      "Mann Whitney U test: p=3.217257322741108e-69. Different distributions.\n",
      "=====Layer 6=====\n",
      "Correct words (total 7617): avg score: -188.45, std 191.42\n",
      "Incorrect words (total 1402): avg score: -275.89, std 166.27\n",
      "Mann Whitney U test: p=5.567940460930247e-68. Different distributions.\n",
      "=====Layer 7=====\n",
      "Correct words (total 7617): avg score: -200.51, std 182.75\n",
      "Incorrect words (total 1402): avg score: -283.17, std 158.39\n",
      "Mann Whitney U test: p=5.491516063127831e-68. Different distributions.\n",
      "=====Layer 8=====\n",
      "Correct words (total 7617): avg score: -229.04, std 176.49\n",
      "Incorrect words (total 1402): avg score: -303.31, std 153.40\n",
      "Mann Whitney U test: p=1.5985371652362302e-58. Different distributions.\n",
      "=====Layer 9=====\n",
      "Correct words (total 7617): avg score: -252.06, std 188.60\n",
      "Incorrect words (total 1402): avg score: -337.66, std 171.71\n",
      "Mann Whitney U test: p=2.6782486211590454e-65. Different distributions.\n",
      "=====Layer 10=====\n",
      "Correct words (total 7617): avg score: -202.75, std 205.37\n",
      "Incorrect words (total 1402): avg score: -332.59, std 224.99\n",
      "Mann Whitney U test: p=3.361997331419623e-99. Different distributions.\n",
      "=====Layer 11=====\n",
      "Correct words (total 7617): avg score: -121.82, std 203.90\n",
      "Incorrect words (total 1402): avg score: -267.44, std 259.14\n",
      "Mann Whitney U test: p=8.844126839343168e-108. Different distributions.\n",
      "=====Layer 12=====\n",
      "Correct words (total 7617): avg score: 554.40, std 233.58\n",
      "Incorrect words (total 1402): avg score: 484.81, std 260.40\n",
      "Mann Whitney U test: p=2.6748857071849844e-31. Different distributions.\n",
      "true_false_bin done in 45.79 seconds.\n"
     ]
    }
   ],
   "source": [
    "@timed_func\n",
    "def true_false_bin(samples):\n",
    "    test_sentences = [item['sentence'] for item in samples]\n",
    "    all_tokens, gmm_scores = anomaly_model.gmm_score(test_sentences)\n",
    "    \n",
    "    for layer in range(13):\n",
    "        print (\"=====Layer {}=====\".format(layer))\n",
    "        scores_correct, scores_typo = [], []\n",
    "        for i, sample in enumerate(samples):\n",
    "            if sample['errors'][0]['start_pos'] == -1:  # This sentence is correct\n",
    "                scores_correct += gmm_scores[i][layer].tolist()\n",
    "            else:\n",
    "                # These T/F sentinels mark the errors of this sentence\n",
    "                st_word_len = len(test_sentences[i].split())\n",
    "                tr_word_len = len(all_tokens[i])\n",
    "                assert tr_word_len == st_word_len  # Verified in verify_lengths. Safety check here\n",
    "                \n",
    "                sentinels = np.ones(st_word_len)\n",
    "                for gerr in sample['errors']:\n",
    "                    sentinels[gerr['start_pos']: gerr['end_pos']] = 0  # broadcast\n",
    "                \n",
    "                for j in range(len(sentinels)):\n",
    "                    if sentinels[j]:\n",
    "                        scores_correct.append(gmm_scores[i][layer,j])\n",
    "                    else:\n",
    "                        scores_typo.append(gmm_scores[i][layer,j])\n",
    "        print (\"Correct words (total {}): avg score: {:.2f}, std {:.2f}\".format(\n",
    "            len(scores_correct),\n",
    "            np.mean(scores_correct), np.std(scores_correct)\n",
    "        ))\n",
    "        print (\"Incorrect words (total {}): avg score: {:.2f}, std {:.2f}\".format(\n",
    "            len(scores_typo),\n",
    "            np.mean(scores_typo), np.std(scores_typo)\n",
    "        ))\n",
    "        stat, p = mannwhitneyu(scores_correct, scores_typo)\n",
    "        # https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/\n",
    "        # Non-normal for both arrays\n",
    "        u_test_res = \"Same\" if p>0.05 else \"Different\"\n",
    "        print (\"Mann Whitney U test: p={}. {} distributions.\".format(p, u_test_res))\n",
    "        \n",
    "true_false_bin(gec_samples[500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations up till now:  \n",
    "1. There are separations between the GMM scores for \"correct words\" and \"incorrect words\".  \n",
    "2. Except for layer 12, the `p` values in general decrease as layers go up. This might indicate that higher layers are more surprised at grammar errors.  \n",
    "3. The large std indicate that there might not be a clear-cut threshold, for us to say \"when the surprisal score is beyond / below this threshold, this is grammar error\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level grammar error detection\n",
    "- Can we tune on dev set to find a threshold?  \n",
    "- Use this performance to contrast to the next step (residualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed_func\n",
    "def find_threshold(samples):\n",
    "    test_sentences = [item['sentence'] for item in samples]\n",
    "    all_tokens, gmm_scores = anomaly_model.gmm_score(test_sentences)\n",
    "    \n",
    "    # TODO - find threshold on gec_dev (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level grammar error detection with residualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed_func\n",
    "def ged_with_residualization(samples):\n",
    "    raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
