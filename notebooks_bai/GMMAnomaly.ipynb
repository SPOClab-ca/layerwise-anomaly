{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM Anomaly Detection in contextual tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "import random\n",
    "import sklearn.mixture\n",
    "\n",
    "import src.sent_encoder\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'roberta-base'\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick random subset of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bnc.pkl', 'rb') as f:\n",
    "  bnc_sentences = pickle.load(f)\n",
    "\n",
    "random.seed(12345)\n",
    "bnc_sentences = random.sample(bnc_sentences, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed them through BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = src.sent_encoder.SentEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnc_vecs = enc.contextual_token_vecs(bnc_sentences, layer=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GMM, test on ungrammatical sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
       "                means_init=None, n_components=1, n_init=1, precisions_init=None,\n",
       "                random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "                verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm = sklearn.mixture.GaussianMixture()\n",
    "gmm.fit(bnc_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_new_sentence(sent):\n",
    "  ids = [x for x in enc.auto_tokenizer(sent)['input_ids'] if x not in enc.auto_tokenizer.all_special_ids]\n",
    "  sent_vecs = enc.contextual_token_vecs([sent])\n",
    "  assert len(ids) == sent_vecs.shape[0]\n",
    "  \n",
    "  for i in range(sent_vecs.shape[0]):\n",
    "    print(enc.auto_tokenizer.decode(ids[i]), gmm.score([sent_vecs[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -24.88312349970215\n",
      " cats -111.1238954929845\n",
      " won -376.85479956653944\n",
      "'t -314.6890912956078\n",
      " eating -401.75939332260396\n",
      " the -16.839375473423047\n",
      " food -34.187998326945376\n",
      " that 13.502896209406344\n",
      " Mary -82.7106539223663\n",
      " gives -203.89372120158964\n",
      " them -220.90611577235813\n",
      ". 207.03518002565397\n"
     ]
    }
   ],
   "source": [
    "infer_new_sentence(\"The cats won't eating the food that Mary gives them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -24.570347497591\n",
      " student -108.71452760265811\n",
      " laughs -88.1599491002903\n",
      ". 207.72688568806518\n"
     ]
    }
   ],
   "source": [
    "infer_new_sentence(\"The student laughs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -67.13459467313692\n",
      " student -185.33300475802707\n",
      " laugh -180.1849407009704\n",
      ". 207.6739630696121\n"
     ]
    }
   ],
   "source": [
    "infer_new_sentence(\"The student laugh.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
