{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM Anomaly Detection in contextual tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import src.sentpair_generator\n",
    "import src.anomaly_model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick random subset of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bnc.pkl', 'rb') as f:\n",
    "  bnc_sentences = pickle.load(f)\n",
    "\n",
    "random.seed(12345)\n",
    "bnc_sentences = random.sample(bnc_sentences, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of GMM score at each layer and word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = src.anomaly_model.AnomalyModel(bnc_sentences, model_name='xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_layer_scores(sent):\n",
    "  tokens, all_layer = model.gmm_score([sent])\n",
    "  tokens = tokens[0]\n",
    "  all_layer = all_layer[0]\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.imshow(all_layer, origin='lower')\n",
    "  plt.xticks(range(len(tokens)), tokens, rotation='vertical')\n",
    "  plt.yticks(range(12), range(12))\n",
    "  plt.ylabel('Layer')\n",
    "  for (j,i),label in np.ndenumerate(all_layer):\n",
    "    plt.text(i, j, int(label), ha='center', va='center', color='white')\n",
    "  plt.show()\n",
    "\n",
    "all_layer_scores(\"The cats won't eating the food that Mary gives them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layer_scores(\"The boxes in the attic may still hold many old photographs and souvenirs.\")\n",
    "all_layer_scores(\"The boxes in the attic may still find many old photographs and souvenirs.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_layer_scores(\"Corey's hamster entertained a nearby backpack and filled it with sawdust.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentgen = src.sentpair_generator.SentPairGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "def process_sentpair_dataset(taskname, category, sent_pairs):\n",
    "  # For debugging, take random 100\n",
    "  if len(sent_pairs) > 100:\n",
    "    sent_pairs = random.sample(sent_pairs, 100)\n",
    "  \n",
    "  scores = []\n",
    "  for layer in range(13):\n",
    "    results = model.eval_sent_pairs(sent_pairs, layer)\n",
    "    scores.extend([{'category': category, 'taskname': taskname, 'layer': layer, 'score': r} for r in results])\n",
    "  scores = pd.DataFrame(scores)\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for taskname, sent_pair_set in sentgen.get_hand_selected().items():\n",
    "  task_scores = process_sentpair_dataset(taskname, sent_pair_set.category, sent_pair_set.sent_pairs)\n",
    "  all_scores.append(task_scores)\n",
    "  \n",
    "  plt.figure(figsize=(10, 5))\n",
    "  ax = sns.boxplot(x='layer', y='score', data=task_scores, color='lightblue')\n",
    "  ax.axhline(0, color='red', linestyle='dashed')\n",
    "  plt.ylim((-abs(task_scores.score.max()), abs(task_scores.score.max())))\n",
    "  plt.xticks(range(0, 13))\n",
    "  #plt.title(f\"{sent_pair_set.category} - {taskname}\")\n",
    "  plt.title(f\"{taskname}\")\n",
    "  plt.xlabel('Layer')\n",
    "  plt.ylabel('GMM Score Difference')\n",
    "  plt.show()\n",
    "all_scores = pd.concat(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar plot of z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = all_scores.groupby(['category', 'taskname', 'layer'], sort=False).score \\\n",
    "  .aggregate(lambda x: np.mean(x) / np.std(x)).reset_index()\n",
    "\n",
    "z_scores['task'] = z_scores.apply(lambda r: f\"{r['category']} - {r['taskname']}\", axis=1)\n",
    "z_scores = z_scores[['task', 'layer', 'score']]\n",
    "z_scores.to_csv('z_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For blimp_all(subtasks=True), need to manually correct for an extremely large value in row 664,\n",
    "# probably some sort of overflow.\n",
    "z_scores = pd.read_csv('z_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(z_scores, row=\"task\", height=2, aspect=4.5)\n",
    "g.map_dataframe(sns.barplot, x=\"layer\", y=\"score\")\n",
    "g.set_axis_labels(\"\", \"Z-Score\")\n",
    "g.set_titles(row_template=\"{row_name}\")\n",
    "g.set(ylim=(-1.5, 3))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
